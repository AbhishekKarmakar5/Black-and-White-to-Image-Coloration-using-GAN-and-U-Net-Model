{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUblMmuwaCRm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39bdwT-7aFKT"
      },
      "source": [
        "# Image Colorization With GANs\n",
        "GANs are the state-of-the-art machine learning models which can generate new data instances from existing ones. They use a very interesting technique, inspired from the Game Theory, to generate realistic samples.\n",
        "\n",
        "In this notebook, we'll use GANs to colorize a grayscale ( B/W ) image. In addition to that, our generator model will have a structure similar to that of a UNet i.e the one with skip connections.\n",
        "\n",
        "# 1. Downloading and Processing the data\n",
        "A dataset of RGB images to train the GAN model whose images consists of various scenes/places.\n",
        "\n",
        "Download the dataset on your machine from here.\n",
        "https://drive.google.com/drive/folders/1VDdLRZAsGp_jAhjZo7w49yMsRf4qS_8d\n",
        "\n",
        "Upload the downloaded .zip file here on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEt1VXYRaPcr",
        "outputId": "a682658f-58e3-4a25-df6b-4e2ec2bfb921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XfJ6GkZc9mm"
      },
      "source": [
        "We'll now parse the images ( RGB images to be precise ) one by one, and transform each one to a grayscale image using PIL's .convert( 'L' ) method. So our dataset will have samples of  ( 𝑔𝑟𝑎𝑦𝑠𝑐𝑎𝑙𝑒 𝑖𝑚𝑎𝑔𝑒 , 𝑅𝐺𝐵 𝑖𝑚𝑎𝑔𝑒 ) \n",
        "\n",
        "We used only a part of our dataset, determined by dataset_split , as Colab's computational power would cease on providing a large number of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13k_kF8-aVsg",
        "outputId": "b5556279-c7bb-47d3-8850-e78d3f35e993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/img_color_data\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/img_color_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6hcEVydbL72"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from tensorflow import keras\n",
        "\n",
        "# The batch size we'll use for training\n",
        "batch_size = 64\n",
        "\n",
        "# Size of the image required to train our model\n",
        "img_size = 120\n",
        "\n",
        "# These many images will be used from the data archive\n",
        "dataset_split = 2000 # In total there are 3000 images\n",
        "\n",
        "master_dir = 'data'\n",
        "x = []\n",
        "y = []\n",
        "for image_file in os.listdir(master_dir)[ 0 : dataset_split ]:\n",
        "    rgb_image = Image.open( os.path.join( master_dir , image_file ) ).resize( ( img_size , img_size ) )\n",
        "    # Normalize the RGB image array\n",
        "    rgb_img_array = (np.asarray( rgb_image ) ) / 255\n",
        "    gray_image = rgb_image.convert( 'L' )\n",
        "    # Normalize the grayscale image array\n",
        "    gray_img_array = ( np.asarray( gray_image ).reshape( ( img_size , img_size , 1 ) ) ) / 255\n",
        "    # Append both the image arrays\n",
        "    x.append( gray_img_array )\n",
        "    y.append( rgb_img_array )\n",
        "\n",
        "# Train-test splitting\n",
        "train_x, test_x, train_y, test_y = train_test_split( np.array(x) , np.array(y) , test_size=0.1 )\n",
        "\n",
        "# Construct tf.data.Dataset object\n",
        "dataset = tf.data.Dataset.from_tensor_slices( ( train_x , train_y ) )\n",
        "dataset = dataset.batch( batch_size )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1CQAdoIcJJ2",
        "outputId": "fa93efb2-c5c0-44b5-b7a7-9a631cbc3022"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1800, 120, 120, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZlUfWw7dZNk"
      },
      "source": [
        "# 2. The GAN\n",
        "In this section, we'll create our GAN model step-by-step with Keras. First, we'll implement the generator then the discriminator and finally the loss functions required by both of them.\n",
        "\n",
        "# A. Generator\n",
        "-> Our generator ( represented as 𝐺 ) will take in grayscale image 𝑥 and produce a RGB image 𝐺(𝑥). Note, 𝑥 will be a tensor of shape ( 𝑏𝑎𝑡𝑐ℎ 𝑠𝑖𝑧𝑒 , 120 , 120 , 1 ) and the output 𝐺(𝑥) will have a shape ( 𝑏𝑎𝑡𝑐ℎ 𝑠𝑖𝑧𝑒 , 120 , 120 , 3 )\n",
        "\n",
        "-> Our generator will have a encoder-decoder structure, similar to the UNet architecture. Additionally, we use Dilated convolutions to have a larger receptive field.\n",
        "\n",
        "-> We introduce skip connections in our model so as to have better flow of information from the encoder to the decoder.-> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVD5jqVIdW8t"
      },
      "outputs": [],
      "source": [
        "def get_generator_model():\n",
        "    inputs = tf.keras.layers.Input( shape=( img_size , img_size , 1 ) )\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D( 16 , kernel_size=(3, 3) , strides=1, padding=\"same\")( inputs )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1,  padding=\"same\")( conv1 )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1,  padding=\"same\")( conv1 )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D( 32 , kernel_size=(3, 3) , strides=1,  padding=\"same\")( conv1 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\")( conv2 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\")( conv2 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv2D( 64 , kernel_size=(3,3) , strides=1, padding=\"same\")( conv2 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1,  padding=\"same\")( conv3 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1,  padding=\"same\")( conv3 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "\n",
        "    bottleneck = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='tanh' , padding='same' )( conv3 )\n",
        "\n",
        "    concat_1 = tf.keras.layers.Concatenate()( [ bottleneck , conv3 ] )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu',  padding=\"same\")( concat_1 )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu',  padding=\"same\")( conv_up_3 )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu', padding=\"same\")( conv_up_3 )\n",
        "\n",
        "    concat_2 = tf.keras.layers.Concatenate()( [ conv_up_3 , conv2 ] )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu',  padding=\"same\")( concat_2 )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu',  padding=\"same\")( conv_up_2 )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu',  padding=\"same\")( conv_up_2 )\n",
        "\n",
        "    concat_3 = tf.keras.layers.Concatenate()( [ conv_up_2 , conv1 ] )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu',  padding=\"same\")( concat_3 )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu',  padding=\"same\")( conv_up_1 )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 3 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu',  padding=\"same\")( conv_up_1 )\n",
        "\n",
        "    model = tf.keras.models.Model( inputs , conv_up_1 )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWiGfvQ4fuZu",
        "outputId": "c267657b-c60a-47d7-ec2f-6c220db9240c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 120, 120, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 120, 120, 16  160         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 120, 120, 16  0           ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 120, 120, 32  4640        ['leaky_re_lu[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 120, 120, 32  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 120, 120, 32  9248        ['leaky_re_lu_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 120, 120, 32  0           ['conv2d_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 120, 120, 32  9248        ['leaky_re_lu_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 120, 120, 32  0           ['conv2d_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 120, 120, 64  18496       ['leaky_re_lu_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 120, 120, 64  0           ['conv2d_4[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 120, 120, 64  36928       ['leaky_re_lu_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 120, 120, 64  0           ['conv2d_5[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 120, 120, 64  36928       ['leaky_re_lu_5[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 120, 120, 64  0           ['conv2d_6[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 120, 120, 12  73856       ['leaky_re_lu_6[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 120, 120, 12  0           ['conv2d_7[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 120, 120, 12  147584      ['leaky_re_lu_7[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 120, 120, 12  0           ['conv2d_8[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 120, 120, 12  147584      ['leaky_re_lu_8[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 120, 120, 25  0           ['conv2d_9[0][0]',               \n",
            "                                6)                                'leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 120, 120, 12  295040     ['concatenate[0][0]']            \n",
            " ose)                           8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 120, 120, 12  147584     ['conv2d_transpose[0][0]']       \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 120, 120, 64  204864     ['conv2d_transpose_1[0][0]']     \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 120, 120, 12  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                8)                                'leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 120, 120, 64  73792      ['concatenate_1[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 120, 120, 64  36928      ['conv2d_transpose_3[0][0]']     \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 120, 120, 32  51232      ['conv2d_transpose_4[0][0]']     \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 120, 120, 64  0           ['conv2d_transpose_5[0][0]',     \n",
            "                                )                                 'leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 120, 120, 32  18464      ['concatenate_2[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 120, 120, 32  9248       ['conv2d_transpose_6[0][0]']     \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2DTran  (None, 120, 120, 3)  2403       ['conv2d_transpose_7[0][0]']     \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,324,227\n",
            "Trainable params: 1,324,227\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gen1 = get_generator_model()\n",
        "gen1.summary() # high level summary of our generator network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap3df-eMf1JK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVjqorIUhjic"
      },
      "source": [
        "# B. Discriminator\n",
        "The discriminator model, represented as  𝐷 , will take in the real image  𝑦  ( from the training data ) and the generated image  𝐺(𝑥)  ( from the generator ) to output two probabilities.\n",
        "\n",
        "We train the discriminator in such a manner that is able to differentiate the real images and the generated images. So, we train the model such that  𝑦  produces a output of  1.0  and  𝐺(𝑥)  produces an output of  0.0 .\n",
        "Note that instead of using hard labels like  1.0  and  0.0 , we use soft labels which are close to 1 and 0. So for a hard label of  1.0 , the soft label will be  (1−𝜖)  where  𝜖  is picked uniformly from  (0,0.1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7T-lvR5hlev"
      },
      "outputs": [],
      "source": [
        "def get_discriminator_model():\n",
        "    layers = [\n",
        "        tf.keras.layers.Conv2D( 32 , kernel_size=(3 , 3) , strides=1 , padding=\"same\", activation='relu' , input_shape=( 120 , 120 , 3 ) ),\n",
        "        tf.keras.layers.Conv2D( 32 , kernel_size=( 3, 3 ) , strides=1, padding=\"same\",  activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\", activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\", activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\", activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\", activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\", activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, padding=\"same\", activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense( 512, activation='relu'  )  ,\n",
        "        tf.keras.layers.Dense( 128 , activation='relu' ) ,\n",
        "        tf.keras.layers.Dense( 16 , activation='relu' ) ,\n",
        "        tf.keras.layers.Dense( 1 , activation='sigmoid' ) \n",
        "    ]\n",
        "    model = tf.keras.models.Sequential( layers )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wwojuy7iMPa",
        "outputId": "7f0033fc-9700-446e-f4ef-6bf19003119d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 120, 120, 32)      896       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 120, 120, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 60, 60, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 60, 60, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 30, 30, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 30, 30, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 15, 15, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               6423040   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                2064      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,663,041\n",
            "Trainable params: 7,663,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "dis = get_discriminator_model()\n",
        "dis.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPQNzNAkiQmN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHVzIq_uiZwb"
      },
      "source": [
        "# C. Loss Functions\n",
        "We'll now implement the loss functions for our GAN model. As you might know that we have two loss functions, one for the generator and another for the discriminator.\n",
        "\n",
        "For our generator, we'll use the L2/MSE loss function.\n",
        "For optimization, we use the Adam optimizer with a learning rate of 0.0005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDzJOkyoia_p"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output , real_y):\n",
        "    real_y = tf.cast( real_y , 'float32' )\n",
        "    return mse( fake_output , real_y )\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "\n",
        "generator = get_generator_model()\n",
        "discriminator = get_discriminator_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg62Q9rqichq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyDvc1XZifgq"
      },
      "source": [
        "# 3. Training The GAN\n",
        "So finally, we'll train our GAN on the dataset, we prepared earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSoNuOURigiY"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step( input_x , real_y ):\n",
        "   \n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate an image -> G( x )\n",
        "        generated_images = generator( input_x , training=True)\n",
        "        # Probability that the given image is real -> D( x )\n",
        "        real_output = discriminator( real_y, training=True)\n",
        "        # Probability that the given image is the one generated -> D( G( x ) )\n",
        "        generated_output = discriminator(generated_images, training=True)\n",
        "        \n",
        "        # L2 Loss -> || y - G(x) ||^2\n",
        "        gen_loss = generator_loss( generated_images , real_y )\n",
        "        # Log loss for the discriminator\n",
        "        disc_loss = discriminator_loss( real_output, generated_output )\n",
        "    \n",
        "    #tf.keras.backend.print_tensor( tf.keras.backend.mean( gen_loss ) )\n",
        "    #tf.keras.backend.print_tensor( gen_loss + disc_loss )\n",
        "\n",
        "    # Compute the gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Optimize with Adam\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwpURBdtiiM5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pGn7DZCiknO"
      },
      "source": [
        "# Run the cell below, to start the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCPYDnmJilgX",
        "outputId": "967fe260-e6a1-44fa-98f1-b12f587fb8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "for e in range( num_epochs ):\n",
        "    print(e)\n",
        "    for ( x , y ) in dataset:      \n",
        "        # print( x.shape ) # Here ( x , y ) represents a batch from our training dataset.\n",
        "        train_step( x , y )      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyP3msRaislN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHflk1rssn-M"
      },
      "source": [
        "# 4. Results\n",
        "We plotted the input, output and the original images respectively, from a part of the dataset to find out the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IjoG3SQso12"
      },
      "outputs": [],
      "source": [
        "y = generator( test_x[0 : ] ).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWgqeeOntFbW"
      },
      "outputs": [],
      "source": [
        "for i in range(len(test_x)):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  or_image = plt.subplot(3,3,1)\n",
        "  or_image.set_title('Grayscale Input', fontsize=16)\n",
        "  plt.imshow( test_x[i].reshape((120,120)) , cmap='gray' )\n",
        "\n",
        "  in_image = plt.subplot(3,3,2)    \n",
        "  image = Image.fromarray( ( y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "  image = np.asarray( image )\n",
        "  in_image.set_title('Colorized Output', fontsize=16)\n",
        "  plt.imshow( image )\n",
        "\n",
        "  ou_image = plt.subplot(3,3,3)\n",
        "  image = Image.fromarray( ( test_y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "  ou_image.set_title('Ground Truth', fontsize=16)\n",
        "  plt.imshow( image )\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7bJuXR3tbYN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}